{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Halla avnit! Velkommen til jupyter project!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Veggies</th>\n",
       "      <th>HvyAlcoholConsump</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  Veggies  HvyAlcoholConsump  \\\n",
       "0                   0.0           0.0     0.0      1.0                0.0   \n",
       "1                   0.0           1.0     0.0      0.0                0.0   \n",
       "2                   0.0           0.0     1.0      0.0                0.0   \n",
       "3                   0.0           1.0     1.0      1.0                0.0   \n",
       "4                   0.0           1.0     1.0      1.0                0.0   \n",
       "\n",
       "   GenHlth  DiffWalk   Age  \n",
       "0      5.0       1.0   9.0  \n",
       "1      3.0       0.0   7.0  \n",
       "2      5.0       1.0   9.0  \n",
       "3      2.0       0.0  11.0  \n",
       "4      2.0       0.0  11.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "file_path = 'diabetes_binary_classification_data.csv'\n",
    "# Try specifying the encoding\n",
    "data = pd.read_csv(file_path, encoding='ISO-8859-1')  # or use 'latin1'\n",
    "data.head()\n",
    "# Drop the columns that are less relevant ('Sex', 'Education', 'Income')\n",
    "filtered_data = data.drop(columns=[\"Sex\", \"Education\", \"Income\", \"AnyHealthcare\", \"NoDocbcCost\", \"MentHlth\", \"PhysHlth\"])\n",
    "\n",
    "xgb_gpu = XGBClassifier(tree_method='gpu_hist', random_state=42, eval_metric='aucpr')\n",
    "\n",
    "\n",
    "# Display the first few rows of the filtered dataset\n",
    "filtered_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_binary       253680 non-null  float64\n",
      " 1   HighBP                253680 non-null  float64\n",
      " 2   HighChol              253680 non-null  float64\n",
      " 3   CholCheck             253680 non-null  float64\n",
      " 4   BMI                   253680 non-null  float64\n",
      " 5   Smoker                253680 non-null  float64\n",
      " 6   Stroke                253680 non-null  float64\n",
      " 7   HeartDiseaseorAttack  253680 non-null  float64\n",
      " 8   PhysActivity          253680 non-null  float64\n",
      " 9   Fruits                253680 non-null  float64\n",
      " 10  Veggies               253680 non-null  float64\n",
      " 11  HvyAlcoholConsump     253680 non-null  float64\n",
      " 12  AnyHealthcare         253680 non-null  float64\n",
      " 13  NoDocbcCost           253680 non-null  float64\n",
      " 14  GenHlth               253680 non-null  float64\n",
      " 15  MentHlth              253680 non-null  float64\n",
      " 16  PhysHlth              253680 non-null  float64\n",
      " 17  DiffWalk              253680 non-null  float64\n",
      " 18  Sex                   253680 non-null  float64\n",
      " 19  Age                   253680 non-null  float64\n",
      " 20  Education             253680 non-null  float64\n",
      " 21  Income                253680 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8657954903815831\n",
      "ROC-AUC Score: 0.8263699633458219\n",
      "Confusion Matrix:\n",
      "[[42771   968]\n",
      " [ 5841  1156]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.98      0.93     43739\n",
      "         1.0       0.54      0.17      0.25      6997\n",
      "\n",
      "    accuracy                           0.87     50736\n",
      "   macro avg       0.71      0.57      0.59     50736\n",
      "weighted avg       0.83      0.87      0.83     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load and split the data into features and target\n",
    "X = data.drop(columns=[\"Diabetes_binary\"])  # Features\n",
    "y = data[\"Diabetes_binary\"]  # Target\n",
    "\n",
    "# Split into training and test sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the logistic regression model\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = log_reg.predict(X_test)\n",
    "y_pred_proba = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 384 candidates, totalling 1152 fits\n",
      "Best Parameters for Precision: {'alpha': 1, 'colsample_bytree': 0.8, 'lambda': 1, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 0.8}\n",
      "\n",
      "Classification Report after Grid Search for Precision:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      1.00      0.93     43739\n",
      "         1.0       0.65      0.01      0.02      6997\n",
      "\n",
      "    accuracy                           0.86     50736\n",
      "   macro avg       0.76      0.51      0.47     50736\n",
      "weighted avg       0.83      0.86      0.80     50736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set up a parameter grid for precision tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1],\n",
    "    'alpha': [0.1, 1],  # L1 regularization\n",
    "    'lambda': [0.1, 1],  # L2 regularization\n",
    "    'min_child_weight': [1, 3, 5]  # Controls complexity\n",
    "}\n",
    "\n",
    "# Perform grid search with a focus on precision\n",
    "grid_search_precision = GridSearchCV(estimator=XGBClassifier(random_state=42, eval_metric='aucpr'),\n",
    "                                     param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='precision')\n",
    "\n",
    "grid_search_precision.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters for precision\n",
    "print(f\"Best Parameters for Precision: {grid_search_precision.best_params_}\")\n",
    "\n",
    "# Evaluate the model with the best parameters\n",
    "y_pred_grid_precision = grid_search_precision.predict(X_test)\n",
    "print(\"\\nClassification Report after Grid Search for Precision:\\n\", classification_report(y_test, y_pred_grid_precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_model_precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plot_importance\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot feature importances\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m plot_importance(\u001b[43mxgb_model_precision\u001b[49m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_model_precision' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from xgboost import plot_importance\n",
    "\n",
    "# Plot feature importances\n",
    "plot_importance(xgb_model_precision)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of feature binning for Age\n",
    "filtered_data['Age_bin'] = pd.cut(filtered_data['Age'], bins=[0, 30, 50, 65, 100], labels=['Young', 'Middle Age', 'Senior', 'Elderly'])\n",
    "\n",
    "# Interaction feature\n",
    "filtered_data['BMI_Age'] = filtered_data['BMI'] * filtered_data['Age']\n",
    "\n",
    "# Re-run the grid search after these new features are added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 384 candidates, totalling 1152 fits\n",
      "\n",
      "Classification Report with SMOTE and Class Weights:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.55      0.70     65605\n",
      "         1.0       0.24      0.90      0.38     10499\n",
      "\n",
      "    accuracy                           0.60     76104\n",
      "   macro avg       0.61      0.72      0.54     76104\n",
      "weighted avg       0.87      0.60      0.66     76104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to resample the data\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initialize XGBClassifier with class weights\n",
    "xgb_weighted_smote = XGBClassifier(random_state=42, eval_metric='aucpr', scale_pos_weight=pos_weight)\n",
    "\n",
    "# Perform grid search on the resampled data\n",
    "grid_search_weighted_smote = GridSearchCV(estimator=xgb_weighted_smote, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='precision')\n",
    "grid_search_weighted_smote.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Get predictions on the test set\n",
    "y_pred_weighted_smote = grid_search_weighted_smote.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nClassification Report with SMOTE and Class Weights:\\n\", classification_report(y_test, y_pred_weighted_smote))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetes_binary\n",
      "0.0    50.0\n",
      "1.0    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#this balnces the dataset\n",
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = data.drop('Diabetes_binary', axis=1)\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "# Initialize the RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Apply undersampling to the data\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# Combine the resampled features and target into a new DataFrame\n",
    "df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='Diabetes_binary')], axis=1)\n",
    "\n",
    "# Check the new distribution of the target variable after undersampling\n",
    "print(df_resampled['Diabetes_binary'].value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 384 candidates, totalling 1152 fits\n",
      "Best Parameters for Precision: {'alpha': 0.1, 'colsample_bytree': 0.8, 'lambda': 1, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 200, 'subsample': 1}\n",
      "\n",
      "Classification Report after Grid Search for Precision:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.70      0.74      7090\n",
      "         1.0       0.73      0.80      0.76      7049\n",
      "\n",
      "    accuracy                           0.75     14139\n",
      "   macro avg       0.75      0.75      0.75     14139\n",
      "weighted avg       0.75      0.75      0.75     14139\n",
      "\n",
      "\n",
      "New distribution of target variable after undersampling:\n",
      "Diabetes_binary\n",
      "0.0    50.0\n",
      "1.0    50.0\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Prepare features (X) and target (y)\n",
    "X = data.drop('Diabetes_binary', axis=1)  # Assuming 'data' is your dataset\n",
    "y = data['Diabetes_binary']\n",
    "\n",
    "# Initialize the RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "# Apply undersampling to the data\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up a parameter grid for precision tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1],\n",
    "    'colsample_bytree': [0.8, 1],\n",
    "    'alpha': [0.1, 1],  # L1 regularization\n",
    "    'lambda': [0.1, 1],  # L2 regularization\n",
    "    'min_child_weight': [1, 3, 5]  # Controls complexity\n",
    "}\n",
    "\n",
    "# Perform grid search with a focus on precision\n",
    "grid_search_precision = GridSearchCV(estimator=XGBClassifier(random_state=42, eval_metric='aucpr'),\n",
    "                                     param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='precision')\n",
    "\n",
    "# Fit the model with the resampled training data\n",
    "grid_search_precision.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters for precision\n",
    "print(f\"Best Parameters for Precision: {grid_search_precision.best_params_}\")\n",
    "\n",
    "# Evaluate the model with the best parameters on the test data\n",
    "y_pred_grid_precision = grid_search_precision.predict(X_test)\n",
    "print(\"\\nClassification Report after Grid Search for Precision:\\n\", classification_report(y_test, y_pred_grid_precision))\n",
    "\n",
    "# Check the new distribution of the target variable after undersampling\n",
    "df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='Diabetes_binary')], axis=1)\n",
    "print(\"\\nNew distribution of target variable after undersampling:\")\n",
    "print(df_resampled['Diabetes_binary'].value_counts(normalize=True) * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
